{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ConvE import ConvE, ConvE_args\n",
    "from utils.loaders import load_data\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ConvE_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\odhra\\Documents\\graph_project\\allosteric_reasonings\\data\\processed\\triplets.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "\n",
    "with open(r'C:\\Users\\odhra\\Documents\\graph_project\\allosteric_reasonings\\data\\processed\\triplet_lookup.pickle', 'rb') as handle:\n",
    "    lookup = pickle.load(handle)\n",
    "\n",
    "with open(r'C:\\Users\\odhra\\Documents\\graph_project\\allosteric_reasonings\\data\\processed\\ASD_dictionary.pickle', 'rb') as handle:\n",
    "    ASD_dictionary = pickle.load(handle)\n",
    "\n",
    "\n",
    "with open(r'C:\\Users\\odhra\\Documents\\graph_project\\allosteric_reasonings\\data\\processed\\Sparse_dictionary.pickle', 'rb') as handle:\n",
    "    BCE_dictionary = pickle.load(handle)\n",
    "\n",
    "\n",
    "entities = int(len(lookup)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_batches = 10\n",
    "number_of_epochs = 30\n",
    "x = shuffle(data)\n",
    "test_data = x[:100] #just limit data to the first 100 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_objects, all_relationships, all_subjects = np.split(test_data, 3, axis=1)\n",
    "all_objects = torch.LongTensor(all_objects)\n",
    "all_subjects = torch.squeeze(torch.LongTensor(all_subjects))\n",
    "# all_relationships = torch.LongTensor([a+1 for a in all_relationships])\n",
    "all_relationships = torch.LongTensor(all_relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvE(args = args, num_entities = entities, num_relations=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_torch(a):\n",
    "    oof = BCE_dictionary[(a[0],a[1])]\n",
    "    return((oof.todense()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "70555 4\ntensor([[26620],\n        [31448],\n        [43997],\n        [50237],\n        [51548],\n        [56387],\n        [66924],\n        [67993]])\ntensor(66285)\ntensor(1.0843, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[ 3828],\n        [37372]])\ntensor(43051)\ntensor(0.1334, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[ 2822],\n        [13092],\n        [13495],\n        [18849],\n        [24212],\n        [40427],\n        [42836],\n        [58953],\n        [61703]])\ntensor(56869)\ntensor(0.0432, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[28401],\n        [47833]])\ntensor(3269)\ntensor(0.0110, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[35432],\n        [53803],\n        [54563]])\ntensor(44989)\ntensor(0.0094, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[21029],\n        [60157]])\ntensor(3269)\ntensor(0.0056, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[59151]])\ntensor(3269)\ntensor(0.0018, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[13968]])\ntensor(44989)\ntensor(0.0087, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[19203],\n        [27911],\n        [59837],\n        [68569]])\ntensor(44989)\ntensor(0.0012, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[ 1243],\n        [ 6826],\n        [15588],\n        [20694],\n        [34531],\n        [49237],\n        [50161],\n        [53472],\n        [66330]])\ntensor(44989)\ntensor(0.0012, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[ 3828],\n        [37372]])\ntensor(44989)\ntensor(0.0009, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[ 1243],\n        [ 6826],\n        [15588],\n        [20694],\n        [34531],\n        [49237],\n        [50161],\n        [53472],\n        [66330]])\ntensor(44989)\ntensor(0.0026, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[54662]])\ntensor(44989)\ntensor(0.0005, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[  262],\n        [ 2823],\n        [ 4581],\n        [ 7940],\n        [14179],\n        [24116],\n        [37764],\n        [54330],\n        [59125],\n        [60669],\n        [63720],\n        [67113]])\ntensor(44989)\ntensor(0.0012, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[42396],\n        [57035],\n        [59630]])\ntensor(53090)\ntensor(0.0005, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[6306]])\ntensor(44989)\ntensor(0.0019, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[ 7179],\n        [38058],\n        [49035]])\ntensor(44989)\ntensor(0.0012, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[47309],\n        [48579],\n        [63957]])\ntensor(7730)\ntensor(0.0014, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[ 2822],\n        [13092],\n        [13495],\n        [18849],\n        [24212],\n        [40427],\n        [42836],\n        [58953],\n        [61703]])\ntensor(44989)\ntensor(0.0005, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[65087]])\ntensor(34531)\ntensor(0.0007, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[46408]])\ntensor(15588)\ntensor(0.0009, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[ 3828],\n        [37372]])\ntensor(48813)\ntensor(0.0003, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[54662]])\ntensor(14179)\ntensor(0.0003, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[42396],\n        [57035],\n        [59630]])\ntensor(50237)\ntensor(0.0004, grad_fn=<BinaryCrossEntropyBackward>)\ntensor([[  262],\n        [ 2823],\n        [ 4581],\n        [ 7940],\n        [14179],\n        [24116],\n        [37764],\n        [54330],\n        [59125],\n        [60669],\n        [63720],\n        [67113]])\ntensor(1243)\ntensor(0.0005, grad_fn=<BinaryCrossEntropyBackward>)\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-27ffef75954e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBCE_subj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0moptimiser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# print(pred[0].round().nonzero())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\odhra\\Documents\\graph_project\\allosteric_reasonings\\.alosteric_venv\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\odhra\\Documents\\graph_project\\allosteric_reasonings\\.alosteric_venv\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ConvE(args = args, num_entities = entities, num_relations=4)\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "for epoch in range(number_of_epochs):\n",
    "\n",
    "        model.train() #tells pytorch you are training rather than evaluating, so dropout happens\n",
    "\n",
    "        objects, subjects, relationships  = load_data(test_data, number_of_batches)\n",
    "\n",
    "        for index in range(number_of_batches):\n",
    "\n",
    "            obj = torch.LongTensor(objects[index])\n",
    "            rel = torch.LongTensor(relationships[index])\n",
    "            subj = torch.squeeze(torch.LongTensor(subjects[index]))\n",
    "\n",
    "            obj_sub = np.hstack((objects[index], relationships[index]))\n",
    "            BCE = np.apply_along_axis(get_torch, axis= 1, arr = obj_sub)\n",
    "            BCE_subj = torch.LongTensor(BCE).float()\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "            pred = model.forward(e1 = obj, rel = rel)\n",
    "\n",
    "            loss = model.loss(pred, BCE_subj)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "        # print(pred[0].round().nonzero())\n",
    "        print(BCE_subj[0].nonzero())\n",
    "        _, index = torch.max(pred[0], 0)\n",
    "        print(index)\n",
    "\n",
    "        print(loss)\n",
    "        model.eval()\n",
    "\n",
    "        # print(model.emb_rel(torch.LongTensor([1])))\n",
    "\n",
    "        # outputs = model.forward(e1 = all_objects, rel = all_relationships)\n",
    "        # _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # print('number of correct answers is') \n",
    "        # print((predicted == all_subjects).sum().item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "outputs = model.forward(e1 = all_objects, rel = all_relationships)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[47309],\n        [48579],\n        [63957]])"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "BCE_subj[0].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = outputs.round()\n",
    "predicted = test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[17108],\n        [32085],\n        [39579],\n        [48866],\n        [55546],\n        [69165]])"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "predicted[0].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[17358],\n        [23807]])"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "torch.nonzero(work[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(6.)\ntensor(2.)\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\ntensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
    }
   ],
   "source": [
    "print(sum(predicted[0]))\n",
    "print(sum(work[0]))\n",
    "for index, x in enumerate(predicted):\n",
    "    if torch.all(torch.eq(predicted[index], work[index])) == False:\n",
    "        print(work[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuk = np.hstack((all_objects, all_relationships))\n",
    "please = np.apply_along_axis(get_torch, axis= 1, arr = fuk)\n",
    "work = torch.LongTensor(please).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.forward(e1 = all_objects, rel = all_relationships)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print(predicted)\n",
    "print(predicted/all_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best way to test your system is to train on 100 examples and tests on the 100 same examples - if your model doesn't overfit after a bundle of epochs there is a mistake. \n",
    "# knowledge base models take a long long time to converge. They can take 100s of epochs to converge. YOU SHOULD SHUFFLE YOUR DATA EVERY TIME!!! Don't have the same stuff in each batch. \n",
    "# learn to use the data loader for shuffling. Alternatively do it yourself.  \n",
    "# with BCE you can do label smoothing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()\n",
    "\n",
    "print('emb_grad')\n",
    "print(model.emb_e.weight.grad)\n",
    "\n",
    "loss = model.loss(pred, subj)\n",
    "loss.backward()\n",
    "\n",
    "print('emb_grad')\n",
    "print(model.emb_e.weight.grad)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitalostericvenvvenve042302d83484289899f1ea331a7aba5",
   "display_name": "Python 3.8.2 64-bit ('.alosteric_venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}