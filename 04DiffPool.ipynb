{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader, Data\n",
    "from torch_geometric.nn import DenseSAGEConv, dense_diff_pool\n",
    "\n",
    "from utils.loaders import load_data, get_onehots\n",
    "from utils.evaluation_metrics import SRR, auprc_auroc_ap\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You need to make the DiffPool encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_nodes = 150\n",
    "\n",
    "class MyFilter(object):\n",
    "    def __call__(self, data):\n",
    "        return data.num_nodes <= max_nodes\n",
    "\n",
    "\n",
    "path = osp.join(osp.dirname(osp.realpath('__file__')), '..', 'data',\n",
    "                'PROTEINS_dense')\n",
    "dataset = TUDataset(path, name='PROTEINS', transform=T.ToDense(max_nodes),\n",
    "                    pre_filter=MyFilter())\n",
    "dataset = dataset.shuffle()\n",
    "n = (len(dataset) + 9) // 10\n",
    "test_dataset = dataset[:n]\n",
    "val_dataset = dataset[n:2 * n]\n",
    "train_dataset = dataset[2 * n:]\n",
    "test_loader = DenseDataLoader(test_dataset, batch_size=20)\n",
    "val_loader = DenseDataLoader(val_dataset, batch_size=20)\n",
    "train_loader = DenseDataLoader(train_dataset, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.path_manage import get_files\n",
    "\n",
    "data, lookup, ASD_dictionary, BCE_dictionary, Edge_list, Edge_features, Drug_graph_list, Protein_graph_list = get_files()\n",
    "entities = int(len(lookup)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_protein_nodes = 150\n",
    "max_drug_nodes = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drug_list = list(set(data[:,0]))\n",
    "Protein_list = list(set(data[:,2]))\n",
    "\n",
    "Drug_graph_dict = {x : y for x, y in zip(Drug_list, Drug_graph_list)}\n",
    "Protein_graph_dict = {x : y for x, y in zip(Protein_list, Protein_graph_list)}\n",
    "\n",
    "filtered_data = [x for x in data if not isinstance(Drug_graph_dict[x[0]], str)] \n",
    "filtered_data = [x for x in filtered_data if not isinstance(Protein_graph_dict[x[2]], str)] \n",
    "\n",
    "filtered_data = [x for x in filtered_data if Drug_graph_dict[x[0]].num_nodes <= max_drug_nodes]\n",
    "filtered_data = [x for x in filtered_data if Protein_graph_dict[x[2]].num_nodes <= max_protein_nodes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = np.stack(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protien_ids = list(set(filtered_data[:,2]))\n",
    "protien_ids = torch.LongTensor(protien_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_batches = 5\n",
    "number_of_epochs = 20\n",
    "x = shuffle(filtered_data)\n",
    "dataset = x[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = (len(dataset) + 9) // 10\n",
    "test_dataset = dataset[:n]\n",
    "val_dataset = dataset[n:2 * n]\n",
    "train_dataset = dataset[2 * n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_mask(max_nodes, graph):\n",
    "    num_nodes = graph.num_nodes\n",
    "    num_features = graph.x.shape[1]\n",
    "\n",
    "    mask = np.zeros([max_nodes,max_nodes], dtype = bool)\n",
    "    mask[0:num_nodes][0:num_nodes] = True\n",
    "    mask = torch.DoubleTensor(mask)\n",
    "\n",
    "    node_mask = torch.FloatTensor(np.zeros([max_nodes - num_nodes, num_features]))\n",
    "    nodes = torch.cat([graph.x, node_mask]).double()\n",
    "    \n",
    "    adjacency = np.zeros([max_nodes,max_nodes]) # Check if Dtype int is needed! \n",
    "    edges = graph.edge_index.T\n",
    "    for edge in edges:\n",
    "        adjacency[edge[0]][edge[1]] = 1\n",
    "        adjacency[edge[1]][edge[0]] = 1\n",
    "        # should add weighting here!\n",
    "    adjacency = torch.DoubleTensor(adjacency)\n",
    "\n",
    "    return Data(x =  nodes, adj = adjacency, mask = mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you need to import your graph lists!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_batch = DenseDataLoader([get_adj_mask(max_protein_nodes, Protein_graph_dict[data[2]]) for data in test_dataset], 5)\n",
    "drug_batch = DenseDataLoader([get_adj_mask(max_drug_nodes, Drug_graph_dict[data[0]]) for data in test_dataset], 5)\n",
    "relations = torch.LongTensor(test_dataset[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testo = get_adj_mask(max_protein_nodes, Protein_graph_dict[test_dataset[0,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testo.x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.DiffPool import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_encoder = Diff_Pool_Encoder(max_nodes = 150)\n",
    "drug_encoder = Diff_Pool_Encoder(max_nodes = 150)\n",
    "decoder = DistMult_Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder_Decoder(protein_encoder = protein_encoder, drug_encoder= drug_encoder, decoder = decoder, num_relationships= 4).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "for p, d in zip(protein_batch , drug_batch):\n",
    "    print(d.x.dtype, d.adj.dtype, d.mask.dtype)\n",
    "    print(p.x.dtype, p.adj.dtype, p.mask.dtype)\n",
    "    prediction = model.forward(rel=relations, d_graph=d.x.double(), d_adj=d.adj.double(), d_mask = d.mask.double(), p_graph = p.x.double(), p_adj = p.adj.double(), p_mask= p.mask.double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for proteins, drugs in zip(p_adj, d_adj):\n",
    "    print(proteins.x, drugs.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected object of scalar type Double but got scalar type Float for argument #3 'mat2' in call to _th_addmm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Encoder_Decoder().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, _, _ = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        loss_all += data.y.size(0) * loss.item()\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        pred = model(data.x, data.adj, data.mask)[0].max(dim=1)[1]\n",
    "        correct += pred.eq(data.y.view(-1)).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "best_val_acc = test_acc = 0\n",
    "for epoch in range(1, 151):\n",
    "    train_loss = train(epoch)\n",
    "    val_acc = test(val_loader)\n",
    "    if val_acc > best_val_acc:\n",
    "        test_acc = test(test_loader)\n",
    "        best_val_acc = val_acc\n",
    "    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n",
    "          'Val Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n",
    "                                                     val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Diff-Pool model data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels,\n",
    "                 normalize=False, add_loop=False, lin=True):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        self.add_loop = add_loop\n",
    "\n",
    "        self.conv1 = DenseSAGEConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseSAGEConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseSAGEConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin is True:\n",
    "            self.lin = torch.nn.Linear(2 * hidden_channels + out_channels,\n",
    "                                       out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, 'bn{}'.format(i))(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        batch_size, num_nodes, in_channels = x.size()\n",
    "\n",
    "        x0 = x\n",
    "        x1 = self.bn(1, F.relu(self.conv1(x0, adj, mask, self.add_loop)))\n",
    "        x2 = self.bn(2, F.relu(self.conv2(x1, adj, mask, self.add_loop)))\n",
    "        x3 = self.bn(3, F.relu(self.conv3(x2, adj, mask, self.add_loop)))\n",
    "\n",
    "        x = torch.cat([x1, x2, x3], dim=-1)\n",
    "\n",
    "        if self.lin is not None:\n",
    "            x = F.relu(self.lin(x))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diff_Pool_Encoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "\n",
    "        num_nodes = ceil(0.25 * max_nodes)\n",
    "        self.gnn1_pool = GNN(3, 64, num_nodes, add_loop=True)\n",
    "        self.gnn1_embed = GNN(3, 64, 64, add_loop=True, lin=False)\n",
    "\n",
    "        num_nodes = ceil(0.25 * num_nodes)\n",
    "        self.gnn2_pool = GNN(3 * 64, 64, num_nodes)\n",
    "        self.gnn2_embed = GNN(3 * 64, 64, 64, lin=False)  # self.lin1 = torch.nn.Linear(3 * 64, 64)\n",
    "        self.gnn3_embed = GNN(3 * 64, 64, 64, lin=False)   # self.lin2 = torch.nn.Linear(64, 6)   \n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask) #, print(x.shape)\n",
    "        x, adj, l1, e1 = dense_diff_pool(x, adj, s, mask) #, print(x.shape)\n",
    " \n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj) #, print(x.shape)\n",
    "        x, adj, l2, e2 = dense_diff_pool(x, adj, s) #, print(x.shape)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)#, print(x.shape)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        return(x)  #print(x.shape) #x= F.relu(self.lin1(x)) #x= self.lin2(x)                       #return F.log_softmax(x, dim=-1), l1+l2, e1+e2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistMult_Decoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, args=None, dropout=0.05,\n",
    "    ):\n",
    "        super(DistMult_Decoder, self).__init__()\n",
    "        self.inp_drop = torch.nn.Dropout(dropout)\n",
    "        # self.loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, protein_embedded, drug_embedded, rel_embedded):\n",
    "\n",
    "        drug_embedded = self.inp_drop(drug_embedded)\n",
    "        protein_embedded = self.inp_drop(protein_embedded)\n",
    "        rel_embedded = self.inp_drop(rel_embedded)\n",
    "\n",
    "        print(drug_embedded.shape)\n",
    "        print(protein_embedded.shape)\n",
    "        print(rel_embedded.shape)\n",
    "        pred = torch.mm(drug_embedded * rel_embedded, protein_embedded.transpose(1, 0))\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_Decoder(torch.nn.Module):\n",
    "    def __init__(self, protein_encoder=Diff_Pool_Encoder(), drug_encoder=Diff_Pool_Encoder(), decoder=DistMult_Decoder(), num_relationships=2):\n",
    "        super(Encoder_Decoder, self).__init__()\n",
    "\n",
    "        self.protein_encoder = protein_encoder\n",
    "        self.drug_encoder = drug_encoder\n",
    "        self.decoder = decoder #this is the thing to build\n",
    "\n",
    "        self.emb_rel = torch.nn.Embedding(num_relationships, embedding_dim=64*3, padding_idx=0)\n",
    "\n",
    "    def init(self):\n",
    "        xavier_normal_(self.emb_rel.weight.data)\n",
    "\n",
    "    def forward(self, rel, d_graph, d_adj, d_mask, p_graph, p_adj, p_mask):\n",
    "\n",
    "        rel_embedded = self.emb_rel(rel)\n",
    "        rel_embedded = rel_embedded.squeeze()\n",
    "\n",
    "        drug_embedded = self.drug_encoder(d_graph, d_adj, d_mask)\n",
    "        protein_embedded = self.protein_encoder(d_graph, d_adj, d_mask)\n",
    "\n",
    "        prediction = self.decoder(protein_embedded, drug_embedded, rel_embedded)\n",
    "\n",
    "        print(prediction)\n",
    "        return(prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Encoder_Decoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for data in test_loader:\n",
    "    model.forward(rel=data.y, d_graph=data.x, d_adj=data.adj, d_mask = data.mask, p_graph = data.x, p_adj = data.adj, p_mask= data.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, _, _ = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        loss_all += data.y.size(0) * loss.item()\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        pred = model(data.x, data.adj, data.mask)[0].max(dim=1)[1]\n",
    "        correct += pred.eq(data.y.view(-1)).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "best_val_acc = test_acc = 0\n",
    "for epoch in range(1, 151):\n",
    "    train_loss = train(epoch)\n",
    "    val_acc = test(val_loader)\n",
    "    if val_acc > best_val_acc:\n",
    "        test_acc = test(test_loader)\n",
    "        best_val_acc = val_acc\n",
    "    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n",
    "          'Val Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n",
    "                                                     val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitalostericvenvvenve042302d83484289899f1ea331a7aba5",
   "display_name": "Python 3.8.2 64-bit ('.alosteric_venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}