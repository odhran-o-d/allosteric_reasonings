{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import *\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.path_manage import get_files\n",
    "data, lookup, ASD_dictionary, BCE_dictionary, _, __ = get_files()\n",
    "entities = int(len(lookup)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_dictionary(keys):\n",
    "    vector_size = len(keys)\n",
    "    dictionary = {}\n",
    "    for x_index, x in enumerate(keys):\n",
    "        one_hot = [0] * (vector_size-1)\n",
    "        one_hot.insert(x_index,1)\n",
    "        dictionary[x] = one_hot\n",
    "    return dictionary\n",
    "\n",
    "def get_residue_list(chain):\n",
    "    return [res for res in chain if res.resname in Polypeptide.d3_to_index.keys()]\n",
    "\n",
    "def get_covalent_edges(residues):\n",
    "    return [[index, index-1] for index, x in enumerate(residues) if x._id[1] == ((residues[index-1]._id[1])+1)]\n",
    "\n",
    "def check_proximity(residue_one, residue_two, max_distance = 8) :\n",
    "    \"\"\"Returns the C-alpha distance between two residues\"\"\"\n",
    "    '''C BETA IS PREFEREABLE BUT NEEDS GLYCINE ENCODING'''\n",
    "    diff_vector  = residue_one[\"CA\"].coord - residue_two[\"CA\"].coord\n",
    "    euclidian_distance = np.sqrt(np.sum(diff_vector * diff_vector))\n",
    "    if euclidian_distance < max_distance:     \n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_keys = list(set(data[:,2]))\n",
    "PDB_keys = [ASD_dictionary[lookup[graph_key]]['Protein_ID'] for graph_key in graph_keys]\n",
    "# pdbl = PDBList()\n",
    "# pdbl.download_pdb_files(pdb_codes = PDB_keys, file_format = 'pdb', pdir = 'PDB_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = Polypeptide.d3_to_index.keys()\n",
    "hot_dick = get_one_hot_dictionary(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(residues):\n",
    "    processed_residues = get_residue_list(residues)\n",
    "    covalent_edges = get_covalent_edges(processed_residues)\n",
    "    proximal_edges = [] \n",
    "    for x_index, x in enumerate(processed_residues):\n",
    "        for y_index, y in enumerate(processed_residues):\n",
    "            if y_index >= x_index + 5: \n",
    "                if y > x:\n",
    "                    if check_proximity(x, y):\n",
    "                        proximal_edges.append([x_index,y_index])\n",
    "\n",
    "    all_edges = covalent_edges + proximal_edges\n",
    "    node_features = [hot_dick[res.resname] for res in processed_residues]\n",
    "    edge_index = torch.tensor(all_edges, dtype=torch.long)\n",
    "    node_data = torch.tensor(node_features, dtype=torch.float)\n",
    "    # print(node_data.shape)\n",
    "    graph = Data(x = node_data, edge_index=edge_index.t().contiguous())\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## your graph is directed which probably breaks it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PDBParser()\n",
    "graph_list = []\n",
    "\n",
    "for PDB,graph in tqdm(zip(PDB_keys, graph_keys)):\n",
    "    try:\n",
    "        structure = parser.get_structure('{}'.format(graph), 'PDB_files/pdb{}.ent'.format(PDB.lower()))\n",
    "        model = structure[0]\n",
    "        residues = structure.get_residues()\n",
    "        output_graph = get_graph(residues)\n",
    "        graph_list.append(output_graph)\n",
    "    except:\n",
    "        print(PDB, ' missing')\n",
    "        graph_list.append('{} missing'.format(PDB))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('data/protein_graph_list.pickle', 'wb') as item:\n",
    "#     pickle.dump(graph_list, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/protein_graph_list.pickle', 'rb') as item:\n",
    "    stored_graphs = pickle.load(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_mask(max_nodes, graph):\n",
    "    num_nodes = graph.num_nodes\n",
    "    mask = np.zeros([max_nodes,max_nodes], dtype = bool)\n",
    "    mask[0:num_nodes][0:num_nodes] = True\n",
    "    \n",
    "    adjacency = np.zeros([max_nodes,max_nodes]) # Check if Dtype int is needed! \n",
    "    edges = graph.edge_index.T\n",
    "    for edge in edges:\n",
    "        adjacency[edge[0]][edge[1]] = 1\n",
    "        adjacency[edge[1]][edge[0]] = 1\n",
    "    return Data(x = store.x, adj = adjacency, mask = mask)\n",
    "    \n",
    "\n",
    "max_graph_size = 2000\n",
    "graphs_with_masks = []\n",
    "for store, PDB_key in tqdm(zip(stored_graphs, PDB_keys)):\n",
    "    try:\n",
    "        if store.num_nodes > max_graph_size:\n",
    "            # print(store, ' too big')\n",
    "            graphs_with_masks.append('{} too big'.format(PDB_key))\n",
    "        else:\n",
    "            graphs_with_masks.append(get_adj_mask(max_graph_size, store))\n",
    "    except:\n",
    "        # print(PDB_key, ' missing')\n",
    "        graphs_with_masks.append('{} missing'.format(PDB_key))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_graph_size = 2000\n",
    "graphs_with_masks = []\n",
    "for store, PDB_key in tqdm(zip(stored_graphs, PDB_keys)):\n",
    "    try:\n",
    "        if store.num_nodes > max_graph_size:\n",
    "            # print(store, ' too big')\n",
    "            graphs_with_masks.append('{} too big'.format(PDB_key))\n",
    "        else:\n",
    "            graphs_with_masks.append(get_adj_mask(max_graph_size, store))\n",
    "    except:\n",
    "        # print(PDB_key, ' missing')\n",
    "        graphs_with_masks.append('{} missing'.format(PDB_key))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "print(len(graphs_with_masks))\n",
    "print(len([x for x in graphs_with_masks if not isinstance(x, str)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/protein_graphs_with_masks.pickle', 'wb') as item:\n",
    "    pickle.dump(graphs_with_masks[0], item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is apparently 25 gb"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitalostericvenvvenve042302d83484289899f1ea331a7aba5",
   "display_name": "Python 3.8.2 64-bit ('.alosteric_venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}