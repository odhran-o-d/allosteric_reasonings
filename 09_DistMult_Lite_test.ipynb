{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.DistMult import DistMult_Lite\n",
    "from models.Complex import Complex\n",
    "from models.ConvE import ConvE, ConvE_args\n",
    "\n",
    "from utils.loaders import load_data, get_onehots\n",
    "from utils.evaluation_metrics import SRR, auprc_auroc_ap\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.path_manage import get_files\n",
    "\n",
    "data, lookup, ASD_dictionary, BCE_dictionary, Edge_list, Edge_features, Drug_graph_list, Protein_graph_list = get_files()\n",
    "entities = int(len(lookup)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drug_list = list(set(data[:,0]))\n",
    "# Protein_list = list(set(data[:,2]))\n",
    "\n",
    "# Drug_graph_dict = {x : y for x, y in zip(Drug_list, Drug_graph_list)}\n",
    "# Protein_graph_dict = {x : y for x, y in zip(Protein_list, Protein_graph_list)}\n",
    "\n",
    "# filtered_data = [x for x in data if not isinstance(Drug_graph_dict[x[0]], str)] \n",
    "# filtered_data = [x for x in filtered_data if not isinstance(Protein_graph_dict[x[2]], str)] \n",
    "\n",
    "# data = filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "protien_ids = list(set(data[:,2]))\n",
    "protien_ids = torch.LongTensor(protien_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_batches = 5\n",
    "number_of_epochs = 20\n",
    "x = shuffle(data)\n",
    "test_data = x[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "mean reciporical rank is...\ntensor([0.0074])\nmean reciporical rank is...\ntensor([0.0122])\nmean reciporical rank is...\ntensor([0.0207])\nmean reciporical rank is...\ntensor([0.0503])\nmean reciporical rank is...\ntensor([0.0976])\nmean reciporical rank is...\ntensor([0.1795])\nmean reciporical rank is...\ntensor([0.3067])\nmean reciporical rank is...\ntensor([0.4042])\nmean reciporical rank is...\ntensor([0.5259])\nmean reciporical rank is...\ntensor([0.6396])\nmean reciporical rank is...\ntensor([0.7506])\nmean reciporical rank is...\ntensor([0.8354])\nmean reciporical rank is...\ntensor([0.9126])\nmean reciporical rank is...\ntensor([0.9617])\nmean reciporical rank is...\ntensor([0.9635])\nmean reciporical rank is...\ntensor([0.9803])\nmean reciporical rank is...\ntensor([0.9808])\nmean reciporical rank is...\ntensor([0.9817])\nmean reciporical rank is...\ntensor([0.9900])\nmean reciporical rank is...\ntensor([1.])\n"
    }
   ],
   "source": [
    "model = DistMult_Lite(num_entities = entities, embedding_dim=100, num_relations=4)\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(number_of_epochs):\n",
    "\n",
    "\n",
    "        #training stage \n",
    "        model.train()\n",
    "        objects, subjects, relationships  = load_data(test_data, number_of_batches)\n",
    "\n",
    "        for index in range(number_of_batches):\n",
    "\n",
    "            obj = torch.LongTensor(objects[index])\n",
    "            # print(obj.shape)\n",
    "            rel = torch.LongTensor(relationships[index])\n",
    "            # print(len(rel))\n",
    "            \n",
    "            preprocessed_target = torch.squeeze(torch.LongTensor(subjects[index]))\n",
    "            target = torch.squeeze(torch.stack([(protien_ids == x).nonzero() for x in preprocessed_target]))\n",
    "            # print(len(subj))\n",
    "\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "            pred = model.forward(obj = obj, rel = rel, subj = protien_ids)\n",
    "            \n",
    "            loss = model.loss(pred, target)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "\n",
    "        #evaluation stage\n",
    "        model.eval()\n",
    "        objects, subjects, relationships  = load_data(test_data, number_of_batches)\n",
    "        total_sum_reciporical_rank = torch.zeros(1)\n",
    "\n",
    "        for index in range(number_of_batches):\n",
    "\n",
    "            obj = torch.LongTensor(objects[index])\n",
    "            rel = torch.LongTensor(relationships[index])\n",
    "            \n",
    "            preprocessed_target = torch.squeeze(torch.LongTensor(subjects[index]))\n",
    "            target = torch.squeeze(torch.stack([(protien_ids == x).nonzero() for x in preprocessed_target]),1)\n",
    "\n",
    "            predictions = model.forward(obj = obj, rel = rel, subj = protien_ids)\n",
    "            srr = SRR(predictions, target) \n",
    "            # print(predictions.shape)\n",
    "            # print(targets.shape)\n",
    "            total_sum_reciporical_rank = total_sum_reciporical_rank + srr\n",
    "\n",
    "        print('mean reciporical rank is...')\n",
    "        print(total_sum_reciporical_rank / len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_mask(max_nodes, graph):\n",
    "    num_nodes = graph.num_nodes\n",
    "    mask = np.zeros([max_nodes,max_nodes], dtype = bool)\n",
    "    mask[0:num_nodes][0:num_nodes] = True\n",
    "    \n",
    "    adjacency = np.zeros([max_nodes,max_nodes]) # Check if Dtype int is needed! \n",
    "    edges = graph.edge_index.T\n",
    "    for edge in edges:\n",
    "        adjacency[edge[0]][edge[1]] = 1\n",
    "        adjacency[edge[1]][edge[0]] = 1\n",
    "    return Data(x = store.x, adj = adjacency, mask = mask)\n",
    "    \n",
    "\n",
    "max_graph_size = 2000\n",
    "graphs_with_masks = []\n",
    "for store, PDB_key in tqdm(zip(stored_graphs, PDB_keys)):\n",
    "    try:\n",
    "        if store.num_nodes > max_graph_size:\n",
    "            # print(store, ' too big')\n",
    "            graphs_with_masks.append('{} too big'.format(PDB_key))\n",
    "        else:\n",
    "            graphs_with_masks.append(get_adj_mask(max_graph_size, store))\n",
    "    except:\n",
    "        # print(PDB_key, ' missing')\n",
    "        graphs_with_masks.append('{} missing'.format(PDB_key))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitalostericvenvvenve042302d83484289899f1ea331a7aba5",
   "display_name": "Python 3.8.2 64-bit ('.alosteric_venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}