{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.DistMult import DistMult\n",
    "from utils.loaders import load_data\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\odhra\\Documents\\graph_project\\allosteric_reasonings\\data\\processed\\triplets.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "\n",
    "with open(r'C:\\Users\\odhra\\Documents\\graph_project\\allosteric_reasonings\\data\\processed\\triplet_lookup.pickle', 'rb') as handle:\n",
    "    lookup = pickle.load(handle)\n",
    "\n",
    "with open(r'C:\\Users\\odhra\\Documents\\graph_project\\allosteric_reasonings\\data\\processed\\ASD_dictionary.pickle', 'rb') as handle:\n",
    "    ASD_dictionary = pickle.load(handle)\n",
    "\n",
    "entities = len(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Frequency of unique values of the said array:\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[    0,     1,     2, ..., 70548, 70549, 70550],\n       [34324, 55096, 58973, ...,     9,     1,     2]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(data, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "np.asarray((unique_elements, counts_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'ASD01910968' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-a1e7bed71bd1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlookup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mASD01910968\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ASD01910968' is not defined"
     ]
    }
   ],
   "source": [
    "lookup[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'ASD01910968' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-43f358ae8664>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mASD_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mASD01910968\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ASD01910968' is not defined"
     ]
    }
   ],
   "source": [
    "ASD_dictionary[ASD01910968]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'ASD01910211' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-7d88931d8f43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlookup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mASD01910211\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ASD01910211' is not defined"
     ]
    }
   ],
   "source": [
    "lookup[ASD01910211]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_batches = 50\n",
    "number_of_epochs = 100\n",
    "random.shuffle(data)\n",
    "test_data = data[:100] #just limit data to the first 100 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_objects, all_relationships, all_subjects = np.split(test_data, 3, axis=1)\n",
    "# all_objects = torch.LongTensor(all_objects)\n",
    "# all_subjects = torch.squeeze(torch.LongTensor(all_subjects))\n",
    "# all_relationships = torch.LongTensor(all_relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Frequency of unique values of the said array:\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[23457, 33399, 40874, 50616, 51051, 60379, 62738],\n       [    3,    11,    10,    10,    20,     3,    43]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(all_subjects, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "np.asarray((unique_elements, counts_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Frequency of unique values of the said array:\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[  2],\n       [100]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "random.shuffle(data)\n",
    "test_data = data[:100]\n",
    "all_objects, all_relationships, all_subjects = np.split(test_data, 3, axis=1)\n",
    "unique_elements, counts_elements = np.unique(all_relationships, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "np.asarray((unique_elements, counts_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[43189],\n        [29986],\n        [30351],\n        [38248],\n        [65628],\n        [41173],\n        [29802],\n        [46461],\n        [30351],\n        [60693]])"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "objects, subjects, relationships  = load_data(test_data, number_of_batches)\n",
    "torch.LongTensor(objects[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<generator object Module.parameters at 0x000001EC9B9B6CF0>\n"
    }
   ],
   "source": [
    "model = DistMult(num_entities = entities, embedding_dim=100)\n",
    "print(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()\n",
    "\n",
    "print('emb_grad')\n",
    "print(model.emb_e.weight.grad)\n",
    "\n",
    "loss = model.loss(pred, subj)\n",
    "loss.backward()\n",
    "\n",
    "print('emb_grad')\n",
    "print(model.emb_e.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "number of correct answers is...\n0\nnumber of correct answers is...\n2\nnumber of correct answers is...\n11\nnumber of correct answers is...\n40\nnumber of correct answers is...\n61\nnumber of correct answers is...\n76\nnumber of correct answers is...\n82\nnumber of correct answers is...\n84\nnumber of correct answers is...\n84\nnumber of correct answers is...\n84\nnumber of correct answers is...\n84\nnumber of correct answers is...\n84\nnumber of correct answers is...\n84\nnumber of correct answers is...\n84\nnumber of correct answers is...\n84\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-d7236932c0d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0moptimiser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\odhra\\Documents\\graph_project\\allosteric_reasonings\\.alosteric_venv\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\odhra\\Documents\\graph_project\\allosteric_reasonings\\.alosteric_venv\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "for epoch in range(number_of_epochs):\n",
    "\n",
    "        model.train() #tells pytorch you are training rather than evaluating, so dropout happens\n",
    "\n",
    "        objects, subjects, relationships  = load_data(test_data, number_of_batches)\n",
    "\n",
    "        for index in range(number_of_batches):\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            obj = torch.LongTensor(objects[index])\n",
    "            rel = torch.LongTensor(relationships[index])\n",
    "            subj = torch.squeeze(torch.LongTensor(subjects[index]))\n",
    "\n",
    "            pred = model.forward(e1 = obj, rel = rel)\n",
    "\n",
    "            loss = model.loss(pred, subj)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimiser.step()\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        outputs = model.forward(e1 = all_objects, rel = all_relationships)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        print('number of correct answers is...') \n",
    "        print((predicted == all_subjects).sum().item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best way to test your system is to train on 100 examples and tests on the 100 same examples - if your model doesn't overfit after a bundle of epochs there is a mistake. \n",
    "# knowledge base models take a long long time to converge. They can take 100s of epochs to converge. YOU SHOULD SHUFFLE YOUR DATA EVERY TIME!!! Don't have the same stuff in each batch. \n",
    "# learn to use the data loader for shuffling. Alternatively do it yourself.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with BCE you can do label smoothing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.size()\n",
    "#okay this makes sense its spitting out a prediction!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=0.003, weight_decay=0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitalostericvenvvenve042302d83484289899f1ea331a7aba5",
   "display_name": "Python 3.8.2 64-bit ('.alosteric_venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}