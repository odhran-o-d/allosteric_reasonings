{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.DistMult import DistMult\n",
    "from utils.loaders import load_data, get_onehots\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from utils.evaluation_metrics import SRR, auprc_auroc_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\odhra\\Documents\\graph_project\\allosteric_reasonings\\data\\processed\\triplets.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "\n",
    "with open(r'C:\\Users\\odhra\\Documents\\graph_project\\allosteric_reasonings\\data\\processed\\triplet_lookup.pickle', 'rb') as handle:\n",
    "    lookup = pickle.load(handle)\n",
    "\n",
    "with open(r'C:\\Users\\odhra\\Documents\\graph_project\\allosteric_reasonings\\data\\processed\\ASD_dictionary.pickle', 'rb') as handle:\n",
    "    ASD_dictionary = pickle.load(handle)\n",
    "\n",
    "with open(r'C:\\Users\\odhra\\Documents\\graph_project\\allosteric_reasonings\\data\\processed\\Sparse_dictionary.pickle', 'rb') as handle:\n",
    "    BCE_dictionary = pickle.load(handle)\n",
    "\n",
    "entities = int(len(lookup)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_batches = 5\n",
    "number_of_epochs = 20\n",
    "x = shuffle(data)\n",
    "test_data = x[:50] #just limit data to the first n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_objects, all_relationships, all_subjects = np.split(test_data, 3, axis=1)\n",
    "all_objects = torch.LongTensor(all_objects)\n",
    "all_subjects = torch.squeeze(torch.LongTensor(all_subjects))\n",
    "all_relationships = torch.LongTensor(all_relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "mean reciporical rank is...\ntensor([0.0001])\nmean reciporical rank is...\ntensor([0.0002])\nmean reciporical rank is...\ntensor([0.0005])\nmean reciporical rank is...\ntensor([0.0029])\nmean reciporical rank is...\ntensor([0.0089])\nmean reciporical rank is...\ntensor([0.0311])\nmean reciporical rank is...\ntensor([0.0556])\nmean reciporical rank is...\ntensor([0.0909])\nmean reciporical rank is...\ntensor([0.1657])\nmean reciporical rank is...\ntensor([0.2520])\nmean reciporical rank is...\ntensor([0.3543])\nmean reciporical rank is...\ntensor([0.4861])\nmean reciporical rank is...\ntensor([0.6613])\nmean reciporical rank is...\ntensor([0.7764])\nmean reciporical rank is...\ntensor([0.8411])\nmean reciporical rank is...\ntensor([0.8685])\nmean reciporical rank is...\ntensor([0.9059])\nmean reciporical rank is...\ntensor([0.9312])\nmean reciporical rank is...\ntensor([0.9725])\nmean reciporical rank is...\ntensor([1.])\n"
    }
   ],
   "source": [
    "model = DistMult(num_entities = entities, embedding_dim=100, num_relations=4)\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "for epoch in range(number_of_epochs):\n",
    "\n",
    "\n",
    "        #training stage \n",
    "        model.train()\n",
    "        objects, subjects, relationships  = load_data(test_data, number_of_batches)\n",
    "\n",
    "        for index in range(number_of_batches):\n",
    "\n",
    "            obj = torch.LongTensor(objects[index])\n",
    "            rel = torch.LongTensor(relationships[index])\n",
    "            subj = torch.squeeze(torch.LongTensor(subjects[index]))\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "            pred = model.forward(e1 = obj, rel = rel)\n",
    "            loss = model.loss(pred, subj)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "\n",
    "        #evaluation stage\n",
    "        model.eval()\n",
    "        objects, subjects, relationships  = load_data(test_data, number_of_batches)\n",
    "        total_sum_reciporical_rank = torch.zeros(1)\n",
    "\n",
    "        for index in range(number_of_batches):\n",
    "\n",
    "            obj = torch.LongTensor(objects[index])\n",
    "            rel = torch.LongTensor(relationships[index])\n",
    "            targets = torch.LongTensor(subjects[index])\n",
    "\n",
    "            predictions = model.forward(e1 = obj, rel = rel)\n",
    "            srr = SRR(predictions, targets) \n",
    "            total_sum_reciporical_rank = total_sum_reciporical_rank + srr\n",
    "\n",
    "        print('mean reciporical rank is...')\n",
    "        print(total_sum_reciporical_rank / len(test_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hots = get_onehots(targets, entities)\n",
    "auprc, auroc, ap = auprc_auroc_ap(one_hots, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.99999744876265\n0.9078535353535354\n0.9107070707070707\n"
    }
   ],
   "source": [
    "print(auroc)\n",
    "print(auprc)\n",
    "print(ap)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitalostericvenvvenve042302d83484289899f1ea331a7aba5",
   "display_name": "Python 3.8.2 64-bit ('.alosteric_venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}